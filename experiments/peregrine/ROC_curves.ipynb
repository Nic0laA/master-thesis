{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scur2012/Thesis/master-thesis/.venv/lib/python3.12/site-packages/torch/nn/modules/lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  0%|          | 0/11 [00:00<?, ?it/s]/home/scur2012/Thesis/master-thesis/.venv/lib/python3.12/site-packages/pytorch_lightning/core/module.py:428: UserWarning: You are trying to `self.log()` but the `self.trainer` reference is not registered on the model yet. This is most likely because the model hasn't been passed to the `Trainer`\n",
      "  rank_zero_warn(\n",
      " 82%|████████▏ | 9/11 [00:12<00:02,  1.44s/it]\n",
      "/home/scur2012/Thesis/master-thesis/.venv/lib/python3.12/site-packages/torch/nn/modules/lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  0%|          | 0/23 [00:00<?, ?it/s]/home/scur2012/Thesis/master-thesis/.venv/lib/python3.12/site-packages/pytorch_lightning/core/module.py:428: UserWarning: You are trying to `self.log()` but the `self.trainer` reference is not registered on the model yet. This is most likely because the model hasn't been passed to the `Trainer`\n",
      "  rank_zero_warn(\n",
      " 78%|███████▊  | 18/23 [00:18<00:05,  1.04s/it]\n",
      "/home/scur2012/Thesis/master-thesis/.venv/lib/python3.12/site-packages/torch/nn/modules/lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  0%|          | 0/35 [00:00<?, ?it/s]/home/scur2012/Thesis/master-thesis/.venv/lib/python3.12/site-packages/pytorch_lightning/core/module.py:428: UserWarning: You are trying to `self.log()` but the `self.trainer` reference is not registered on the model yet. This is most likely because the model hasn't been passed to the `Trainer`\n",
      "  rank_zero_warn(\n",
      " 89%|████████▊ | 31/35 [00:26<00:03,  1.19it/s]\n",
      "/home/scur2012/Thesis/master-thesis/.venv/lib/python3.12/site-packages/torch/nn/modules/lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  0%|          | 0/46 [00:00<?, ?it/s]/home/scur2012/Thesis/master-thesis/.venv/lib/python3.12/site-packages/pytorch_lightning/core/module.py:428: UserWarning: You are trying to `self.log()` but the `self.trainer` reference is not registered on the model yet. This is most likely because the model hasn't been passed to the `Trainer`\n",
      "  rank_zero_warn(\n",
      " 91%|█████████▏| 42/46 [00:32<00:03,  1.28it/s]\n",
      "/home/scur2012/Thesis/master-thesis/.venv/lib/python3.12/site-packages/torch/nn/modules/lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  0%|          | 0/46 [00:00<?, ?it/s]/home/scur2012/Thesis/master-thesis/.venv/lib/python3.12/site-packages/pytorch_lightning/core/module.py:428: UserWarning: You are trying to `self.log()` but the `self.trainer` reference is not registered on the model yet. This is most likely because the model hasn't been passed to the `Trainer`\n",
      "  rank_zero_warn(\n",
      " 91%|█████████▏| 42/46 [00:29<00:02,  1.42it/s]\n",
      "/home/scur2012/Thesis/master-thesis/.venv/lib/python3.12/site-packages/torch/nn/modules/lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  0%|          | 0/58 [00:00<?, ?it/s]/home/scur2012/Thesis/master-thesis/.venv/lib/python3.12/site-packages/pytorch_lightning/core/module.py:428: UserWarning: You are trying to `self.log()` but the `self.trainer` reference is not registered on the model yet. This is most likely because the model hasn't been passed to the `Trainer`\n",
      "  rank_zero_warn(\n",
      " 90%|████████▉ | 52/58 [00:37<00:04,  1.40it/s]\n",
      "/home/scur2012/Thesis/master-thesis/.venv/lib/python3.12/site-packages/torch/nn/modules/lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  0%|          | 0/58 [00:00<?, ?it/s]/home/scur2012/Thesis/master-thesis/.venv/lib/python3.12/site-packages/pytorch_lightning/core/module.py:428: UserWarning: You are trying to `self.log()` but the `self.trainer` reference is not registered on the model yet. This is most likely because the model hasn't been passed to the `Trainer`\n",
      "  rank_zero_warn(\n",
      " 90%|████████▉ | 52/58 [00:37<00:04,  1.39it/s]\n",
      "/home/scur2012/Thesis/master-thesis/.venv/lib/python3.12/site-packages/torch/nn/modules/lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  0%|          | 0/58 [00:00<?, ?it/s]/home/scur2012/Thesis/master-thesis/.venv/lib/python3.12/site-packages/pytorch_lightning/core/module.py:428: UserWarning: You are trying to `self.log()` but the `self.trainer` reference is not registered on the model yet. This is most likely because the model hasn't been passed to the `Trainer`\n",
      "  rank_zero_warn(\n",
      " 90%|████████▉ | 52/58 [00:38<00:04,  1.35it/s]\n",
      "/home/scur2012/Thesis/master-thesis/.venv/lib/python3.12/site-packages/torch/nn/modules/lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  0%|          | 0/11 [00:00<?, ?it/s]/home/scur2012/Thesis/master-thesis/.venv/lib/python3.12/site-packages/pytorch_lightning/core/module.py:428: UserWarning: You are trying to `self.log()` but the `self.trainer` reference is not registered on the model yet. This is most likely because the model hasn't been passed to the `Trainer`\n",
      "  rank_zero_warn(\n",
      " 82%|████████▏ | 9/11 [00:13<00:03,  1.51s/it]\n",
      "/home/scur2012/Thesis/master-thesis/.venv/lib/python3.12/site-packages/torch/nn/modules/lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  0%|          | 0/23 [00:00<?, ?it/s]/home/scur2012/Thesis/master-thesis/.venv/lib/python3.12/site-packages/pytorch_lightning/core/module.py:428: UserWarning: You are trying to `self.log()` but the `self.trainer` reference is not registered on the model yet. This is most likely because the model hasn't been passed to the `Trainer`\n",
      "  rank_zero_warn(\n",
      " 78%|███████▊  | 18/23 [00:18<00:05,  1.04s/it]\n",
      "/home/scur2012/Thesis/master-thesis/.venv/lib/python3.12/site-packages/torch/nn/modules/lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  0%|          | 0/35 [00:00<?, ?it/s]/home/scur2012/Thesis/master-thesis/.venv/lib/python3.12/site-packages/pytorch_lightning/core/module.py:428: UserWarning: You are trying to `self.log()` but the `self.trainer` reference is not registered on the model yet. This is most likely because the model hasn't been passed to the `Trainer`\n",
      "  rank_zero_warn(\n",
      " 89%|████████▊ | 31/35 [00:25<00:03,  1.24it/s]\n",
      "/home/scur2012/Thesis/master-thesis/.venv/lib/python3.12/site-packages/torch/nn/modules/lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  0%|          | 0/46 [00:00<?, ?it/s]/home/scur2012/Thesis/master-thesis/.venv/lib/python3.12/site-packages/pytorch_lightning/core/module.py:428: UserWarning: You are trying to `self.log()` but the `self.trainer` reference is not registered on the model yet. This is most likely because the model hasn't been passed to the `Trainer`\n",
      "  rank_zero_warn(\n",
      " 91%|█████████▏| 42/46 [00:30<00:02,  1.37it/s]\n",
      "/home/scur2012/Thesis/master-thesis/.venv/lib/python3.12/site-packages/torch/nn/modules/lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  0%|          | 0/46 [00:00<?, ?it/s]/home/scur2012/Thesis/master-thesis/.venv/lib/python3.12/site-packages/pytorch_lightning/core/module.py:428: UserWarning: You are trying to `self.log()` but the `self.trainer` reference is not registered on the model yet. This is most likely because the model hasn't been passed to the `Trainer`\n",
      "  rank_zero_warn(\n",
      " 91%|█████████▏| 42/46 [00:31<00:02,  1.35it/s]\n",
      "/home/scur2012/Thesis/master-thesis/.venv/lib/python3.12/site-packages/torch/nn/modules/lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  0%|          | 0/58 [00:00<?, ?it/s]/home/scur2012/Thesis/master-thesis/.venv/lib/python3.12/site-packages/pytorch_lightning/core/module.py:428: UserWarning: You are trying to `self.log()` but the `self.trainer` reference is not registered on the model yet. This is most likely because the model hasn't been passed to the `Trainer`\n",
      "  rank_zero_warn(\n",
      " 90%|████████▉ | 52/58 [00:37<00:04,  1.40it/s]\n",
      "/home/scur2012/Thesis/master-thesis/.venv/lib/python3.12/site-packages/torch/nn/modules/lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  0%|          | 0/58 [00:00<?, ?it/s]/home/scur2012/Thesis/master-thesis/.venv/lib/python3.12/site-packages/pytorch_lightning/core/module.py:428: UserWarning: You are trying to `self.log()` but the `self.trainer` reference is not registered on the model yet. This is most likely because the model hasn't been passed to the `Trainer`\n",
      "  rank_zero_warn(\n",
      " 90%|████████▉ | 52/58 [00:36<00:04,  1.42it/s]\n",
      "/home/scur2012/Thesis/master-thesis/.venv/lib/python3.12/site-packages/torch/nn/modules/lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  0%|          | 0/58 [00:00<?, ?it/s]/home/scur2012/Thesis/master-thesis/.venv/lib/python3.12/site-packages/pytorch_lightning/core/module.py:428: UserWarning: You are trying to `self.log()` but the `self.trainer` reference is not registered on the model yet. This is most likely because the model hasn't been passed to the `Trainer`\n",
      "  rank_zero_warn(\n",
      " 90%|████████▉ | 52/58 [00:36<00:04,  1.43it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('/home/scur2012/Thesis/master-thesis/experiments/peregrine')\n",
    "import zarr\n",
    "import pickle\n",
    "import torch\n",
    "\n",
    "import swyft.lightning as sl\n",
    "\n",
    "run_name = 'lowSNR'\n",
    "rnd_id = 1\n",
    "\n",
    "data_directory = '/scratch-shared/scur2012/peregrine_data/bhardwaj2023'\n",
    "\n",
    "for run_name in ['lowSNR', 'highSNR']:\n",
    "    for rid in range(8):\n",
    "        rnd_id = rid+1\n",
    "\n",
    "        # Test the network\n",
    "        match run_name:\n",
    "            case 'highSNR':\n",
    "                match rnd_id:\n",
    "                    case 1: ckpt = 'epoch=91_val_loss=-4.33_train_loss=-4.65_R1.ckpt'\n",
    "                    case 2: ckpt = 'epoch=87_val_loss=-6.76_train_loss=-7.49_R2.ckpt'\n",
    "                    case 3: ckpt = 'epoch=49_val_loss=-7.17_train_loss=-7.48_R3.ckpt'\n",
    "                    case 4: ckpt = 'epoch=70_val_loss=-5.81_train_loss=-5.89_R4.ckpt'\n",
    "                    case 5: ckpt = 'epoch=34_val_loss=-5.53_train_loss=-5.32_R5.ckpt'\n",
    "                    case 6: ckpt = 'epoch=24_val_loss=-5.06_train_loss=-5.13_R6.ckpt'\n",
    "                    case 7: ckpt = 'epoch=72_val_loss=-5.55_train_loss=-5.79_R7.ckpt'\n",
    "                    case 8: ckpt = 'epoch=38_val_loss=-5.33_train_loss=-5.22_R8.ckpt'\n",
    "            case 'lowSNR':\n",
    "                match rnd_id:\n",
    "                    case 1: ckpt = 'epoch=71_val_loss=-4.34_train_loss=-4.30_R1.ckpt'\n",
    "                    case 2: ckpt = 'epoch=71_val_loss=-4.77_train_loss=-4.81_R2.ckpt'\n",
    "                    case 3: ckpt = 'epoch=59_val_loss=-4.36_train_loss=-4.02_R3.ckpt'\n",
    "                    case 4: ckpt = 'epoch=48_val_loss=-4.41_train_loss=-4.19_R4.ckpt'\n",
    "                    case 5: ckpt = 'epoch=50_val_loss=-4.57_train_loss=-4.41_R5.ckpt'\n",
    "                    case 6: ckpt = 'epoch=36_val_loss=-4.47_train_loss=-4.28_R6.ckpt'\n",
    "                    case 7: ckpt = 'epoch=79_val_loss=-4.47_train_loss=-4.27_R7.ckpt'\n",
    "                    case 8: ckpt = 'epoch=65_val_loss=-4.36_train_loss=-4.53_R8.ckpt' \n",
    "\n",
    "        checkpoint_path = f'/scratch-shared/scur2012/peregrine_data/bhardwaj2023/trainer_{run_name}_R{rnd_id}/{ckpt}'\n",
    "\n",
    "        # Load the data from the store\n",
    "\n",
    "        simulation_path = f'/scratch-shared/scur2012/peregrine_data/bhardwaj2023/simulations_{run_name}_R{rnd_id}'\n",
    "        simulation_results = zarr.convenience.open(simulation_path)\n",
    "\n",
    "        zarr_store = sl.ZarrStore(f\"{simulation_path}\")\n",
    "\n",
    "        logratio_path = f'/scratch-shared/scur2012/peregrine_data/bhardwaj2023_v2/logratios_{run_name}/logratios_R{rnd_id}'\n",
    "        if os.path.exists(logratio_path):\n",
    "            with open(logratio_path, 'rb') as f:\n",
    "                logratio_data = pickle.load(f)\n",
    "\n",
    "        # Add function to network to get predictions\n",
    "\n",
    "        import torch\n",
    "        from torch import nn\n",
    "        from torch.functional import F\n",
    "        from toolz.dicttoolz import valmap\n",
    "        from peregrine_network import InferenceNetwork\n",
    "\n",
    "        class InferenceNetworkX(InferenceNetwork):\n",
    "\n",
    "            def get_A_B_samples(self, batch):\n",
    "                \n",
    "                if isinstance(\n",
    "                    batch, list\n",
    "                ):  # multiple dataloaders provided, using second one for contrastive samples\n",
    "                    A = batch[0]\n",
    "                    B = batch[1]\n",
    "                else:  # only one dataloader provided, using same samples for constrative samples\n",
    "                    A = batch\n",
    "                    B = valmap(lambda z: torch.roll(z, 1, dims=0), A)\n",
    "\n",
    "                # Concatenate positive samples and negative (contrastive) examples\n",
    "                x = A\n",
    "                z = {}\n",
    "                for key in B:\n",
    "                    z[key] = torch.cat([A[key], B[key]])\n",
    "                    \n",
    "                return x,z\n",
    "            \n",
    "            def get_logratios_probabilities(self, batch):\n",
    "                \n",
    "                A, B = self.get_A_B_samples(batch)\n",
    "\n",
    "                num_pos = len(list(A.values())[0])  # Number of positive examples\n",
    "                num_neg = len(list(B.values())[0]) - num_pos  # Number of negative examples\n",
    "\n",
    "                out = self(A,B)  # Evaluate network\n",
    "\n",
    "                logratios = self._get_logratios(\n",
    "                    out\n",
    "                )  # Generates concatenated flattened list of all estimated log ratios\n",
    "                \n",
    "                if logratios is not None:\n",
    "                    y = torch.zeros_like(logratios)\n",
    "                    y[:num_pos, ...] = 1\n",
    "                    \n",
    "                    pos_weight = torch.ones_like(logratios[0]) * num_neg / num_pos\n",
    "                    loss_xe = F.binary_cross_entropy_with_logits(\n",
    "                        logratios, y, reduction=\"none\", pos_weight=pos_weight\n",
    "                    )\n",
    "                    \n",
    "                # Use soft-max to convert logratios to probabilities\n",
    "                probabilities = nn.functional.softmax(logratios, dim=0)\n",
    "                \n",
    "                return logratios, probabilities, y, loss_xe\n",
    "        import gw_parameters\n",
    "\n",
    "        conf = gw_parameters.default_conf\n",
    "        bounds = gw_parameters.limits\n",
    "\n",
    "        network_settings = dict(\n",
    "            # Peregrine\n",
    "            shuffling = True,\n",
    "            priors = dict(\n",
    "                int_priors = conf['priors']['int_priors'],\n",
    "                ext_priors = conf['priors']['ext_priors'],\n",
    "            ),\n",
    "            marginals = ((0, 1),),\n",
    "            one_d_only = True,\n",
    "            ifo_list = conf[\"waveform_params\"][\"ifo_list\"],\n",
    "            learning_rate = 5e-4,\n",
    "            training_batch_size = 256,\n",
    "        )\n",
    "\n",
    "        # Load network model\n",
    "        network = InferenceNetworkX(**network_settings)\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "        network.load_state_dict(checkpoint['state_dict'])\n",
    "        # Initialise data loader\n",
    "\n",
    "        train_data = zarr_store.get_dataloader(\n",
    "            num_workers=8,\n",
    "            batch_size=256,\n",
    "            idx_range=[0, int(0.9 * len(zarr_store.data.z_int))],\n",
    "            on_after_load_sample=False,\n",
    "        )\n",
    "\n",
    "        val_data = zarr_store.get_dataloader(\n",
    "            num_workers=8,\n",
    "            batch_size=256,\n",
    "            idx_range=[\n",
    "                int(0.9 * len(zarr_store.data.z_int)),\n",
    "                len(zarr_store.data.z_int) - 1,\n",
    "            ],\n",
    "            on_after_load_sample=None,\n",
    "        )\n",
    "        from tqdm import tqdm\n",
    "\n",
    "        network.eval()\n",
    "        torch.set_grad_enabled(False)\n",
    "\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        network.to(device)\n",
    "\n",
    "        val_losses = []\n",
    "        val_losses_xe = []\n",
    "        logratios = []\n",
    "        probabilities = []\n",
    "        labels = []\n",
    "\n",
    "        for batch_idx, batch in enumerate(tqdm(val_data, total=val_data.dataset.n_samples//val_data.batch_size)):\n",
    "\n",
    "            batch = {key:batch[key].to(device) for key in batch}\n",
    "            \n",
    "            loss = network.validation_step(batch, batch_idx)\n",
    "            val_losses.append(loss.item())\n",
    "            \n",
    "            logratios_probs = network.get_logratios_probabilities(batch)\n",
    "            logratios.append(logratios_probs[0])\n",
    "            probabilities.append(logratios_probs[1])\n",
    "            labels.append(logratios_probs[2])\n",
    "            val_losses_xe.append(logratios_probs[3])\n",
    "\n",
    "        avg_epoch_val_loss = sum(val_losses)/len(val_losses)\n",
    "\n",
    "        logratios_np = torch.concat(logratios).detach().cpu().numpy()\n",
    "        probabilities_np = torch.concat(probabilities).detach().cpu().numpy()\n",
    "        labels_np = torch.concat(labels).cpu().numpy()\n",
    "\n",
    "        import matplotlib.pyplot as plt\n",
    "        from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "        intrinsic_variables = gw_parameters.intrinsic_variables\n",
    "        extrinsic_variables = gw_parameters.extrinsic_variables\n",
    "\n",
    "        plt.figure(1)\n",
    "\n",
    "        # Intrinsic variables plotting\n",
    "        for i, name in enumerate(intrinsic_variables):\n",
    "            fpr, tpr, thresholds = roc_curve(labels_np[:,i], probabilities_np[:,i])\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "\n",
    "            plt.plot(fpr, tpr, lw=1, label=f'{name} (area = {roc_auc:.2f})')\n",
    "        plt.plot([0, 1], [0, 1], color='grey', lw=0.5, linestyle='--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title(f'ROC instrinsic. {run_name} round {rnd_id}')\n",
    "        plt.legend(bbox_to_anchor=(1.7, 1), loc=\"upper right\")\n",
    "        plt.savefig(f'ROC_curve_intrinsic_{run_name}_round_{rnd_id}.png', dpi=600, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "        plt.figure(2)\n",
    "\n",
    "        # Extrinsic variables plotting\n",
    "        for i, name in enumerate(extrinsic_variables):\n",
    "            fpr, tpr, thresholds = roc_curve(labels_np[:,i+10], probabilities_np[:,i+10])\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "\n",
    "            plt.plot(fpr, tpr, lw=1, label=f'{name} (area = {roc_auc:.2f})')\n",
    "        plt.plot([0, 1], [0, 1], color='grey', lw=0.5, linestyle='--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title(f'ROC extrinsic. {run_name} round {rnd_id}')\n",
    "        plt.legend(bbox_to_anchor=(1.7, 1), loc=\"upper right\")\n",
    "        plt.savefig(f'ROC_curve_extrinsic_{run_name}_round_{rnd_id}.png', dpi=600, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
