{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.functional import F\n",
    "import numpy as np\n",
    "import swyft.lightning as sl\n",
    "from toolz.dicttoolz import valmap\n",
    "from sklearn.metrics import roc_curve, auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1D Unet implementation below\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        kernel_size=3,\n",
    "        mid_channels=None,\n",
    "        padding=1,\n",
    "        bias=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv1d(\n",
    "                in_channels,\n",
    "                mid_channels,\n",
    "                kernel_size=kernel_size,\n",
    "                padding=padding,\n",
    "                bias=bias,\n",
    "            ),\n",
    "            nn.BatchNorm1d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(\n",
    "                mid_channels,\n",
    "                out_channels,\n",
    "                kernel_size=kernel_size,\n",
    "                padding=padding,\n",
    "                bias=bias,\n",
    "            ),\n",
    "            nn.BatchNorm1d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "\n",
    "class Down(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, down_sampling=2):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool1d(down_sampling), DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=2):\n",
    "        super().__init__()\n",
    "        self.up = nn.ConvTranspose1d(\n",
    "            in_channels, in_channels // 2, kernel_size=kernel_size, stride=stride\n",
    "        )\n",
    "        self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        diff_signal_length = x2.size()[2] - x1.size()[2]\n",
    "\n",
    "        x1 = F.pad(\n",
    "            x1, [diff_signal_length // 2, diff_signal_length - diff_signal_length // 2]\n",
    "        )\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=1):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv1d(in_channels, out_channels, kernel_size=kernel_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class Unet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_in_channels,\n",
    "        n_out_channels,\n",
    "        sizes=(16, 32, 64, 128, 256),\n",
    "        down_sampling=(2, 2, 2, 2),\n",
    "    ):\n",
    "        super(Unet, self).__init__()\n",
    "        self.inc = DoubleConv(n_in_channels, sizes[0])\n",
    "        self.down1 = Down(sizes[0], sizes[1], down_sampling[0])\n",
    "        self.down2 = Down(sizes[1], sizes[2], down_sampling[1])\n",
    "        self.down3 = Down(sizes[2], sizes[3], down_sampling[2])\n",
    "        self.down4 = Down(sizes[3], sizes[4], down_sampling[3])\n",
    "        self.up1 = Up(sizes[4], sizes[3])\n",
    "        self.up2 = Up(sizes[3], sizes[2])\n",
    "        self.up3 = Up(sizes[2], sizes[1])\n",
    "        self.up4 = Up(sizes[1], sizes[0])\n",
    "        self.outc = OutConv(sizes[0], n_out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        f = self.outc(x)\n",
    "        return f\n",
    "\n",
    "\n",
    "class LinearCompression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearCompression, self).__init__()\n",
    "        self.sequential = nn.Sequential(\n",
    "            nn.LazyLinear(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.LazyLinear(256),\n",
    "            nn.ReLU(),\n",
    "            nn.LazyLinear(64),\n",
    "            nn.ReLU(),\n",
    "            nn.LazyLinear(16),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.sequential(x)\n",
    "\n",
    "\n",
    "class LinearCompression_2d(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearCompression_2d, self).__init__()\n",
    "        self.sequential = nn.Sequential(\n",
    "            nn.LazyLinear(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.LazyLinear(256),\n",
    "            nn.ReLU(),\n",
    "            nn.LazyLinear(128),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.sequential(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceNetwork(sl.SwyftModule):\n",
    "    def __init__(self, **conf):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.one_d_only = True       \n",
    "        self.batch_size = conf[\"batch_size\"]\n",
    "        self.noise_shuffling = True\n",
    "        self.num_params = 15\n",
    "        self.marginals = (0,1),\n",
    "        self.include_noise = True\n",
    "        \n",
    "        self.unet_t = Unet(\n",
    "            n_in_channels=3,\n",
    "            n_out_channels=1,\n",
    "            sizes=(16, 32, 64, 128, 256),\n",
    "            down_sampling=(8, 8, 8, 8),\n",
    "        )\n",
    "        self.unet_f = Unet(\n",
    "            n_in_channels=6,\n",
    "            n_out_channels=1,\n",
    "            sizes=(16, 32, 64, 128, 256),\n",
    "            down_sampling=(2, 2, 2, 2),\n",
    "        )\n",
    "\n",
    "        self.flatten = nn.Flatten(1)\n",
    "        self.linear_t = LinearCompression()\n",
    "        self.linear_f = LinearCompression()\n",
    "\n",
    "        self.logratios_1d = sl.LogRatioEstimator_1dim(\n",
    "            num_features=32, num_params=int(self.num_params), varnames=\"z_total\"\n",
    "        )\n",
    "        \n",
    "        if not self.one_d_only:\n",
    "            self.linear_t_2d = LinearCompression_2d()\n",
    "            self.linear_f_2d = LinearCompression_2d()\n",
    "            self.logratios_2d = sl.LogRatioEstimator_Ndim(\n",
    "                num_features=256, marginals=self.marginals, varnames=\"z_total\"\n",
    "            )\n",
    "            \n",
    "        self.optimizer_init = sl.AdamOptimizerInit(lr=conf[\"learning_rate\"])\n",
    "\n",
    "    def forward(self, A, B):\n",
    "        \n",
    "        if self.noise_shuffling and A[\"d_t\"].size(0) != 1:\n",
    "            noise_shuffling = torch.randperm(self.batch_size)\n",
    "            d_t = A[\"d_t\"] + A[\"n_t\"][noise_shuffling]\n",
    "            d_f_w = A[\"d_f_w\"] + A[\"n_f_w\"][noise_shuffling]\n",
    "        else:\n",
    "            d_t = A[\"d_t\"] + A[\"n_t\"]\n",
    "            d_f_w = A[\"d_f_w\"] + A[\"n_f_w\"]\n",
    "        z_total = B[\"z_total\"]\n",
    "\n",
    "        d_t = self.unet_t(d_t)\n",
    "        d_f_w = self.unet_f(d_f_w)\n",
    "\n",
    "        features_t = self.linear_t(self.flatten(d_t))\n",
    "        features_f = self.linear_f(self.flatten(d_f_w))\n",
    "        features = torch.cat([features_t, features_f], dim=1)\n",
    "        logratios_1d = self.logratios_1d(features, z_total)\n",
    "        return logratios_1d\n",
    "\n",
    "    def _calc_loss(self, batch, randomized=True):\n",
    "        \"\"\"Calcualte batch-averaged loss summed over ratio estimators.\n",
    "\n",
    "        Note: The expected loss for an untrained classifier (with f = 0) is\n",
    "        subtracted.  The initial loss is hence usually close to zero.\n",
    "        \"\"\"\n",
    "        if isinstance(\n",
    "            batch, list\n",
    "        ):  # multiple dataloaders provided, using second one for contrastive samples\n",
    "            A = batch[0]\n",
    "            B = batch[1]\n",
    "        else:  # only one dataloader provided, using same samples for constrative samples\n",
    "            A = batch\n",
    "            B = valmap(lambda z: torch.roll(z, 1, dims=0), A)\n",
    "\n",
    "        # Concatenate positive samples and negative (contrastive) examples\n",
    "        x = A\n",
    "        z = {}\n",
    "        for key in B:\n",
    "            z[key] = torch.cat([A[key], B[key]])\n",
    "\n",
    "        num_pos = len(list(x.values())[0])  # Number of positive examples\n",
    "        num_neg = len(list(z.values())[0]) - num_pos  # Number of negative examples\n",
    "\n",
    "        limits = torch.Tensor(\n",
    "            [0.1, 0.1, 0.05, 1, 0.1, \n",
    "            0.2, 0.05, 0.1, 2, 0.1,\n",
    "            5,0.01, 0.005, 0.2, 0.0001]\n",
    "        )\n",
    "        diff = abs(A['z_total'] - B['z_total'])\n",
    "        softlabels = 1 - diff / limits\n",
    "        softlabels[softlabels<0] = 0\n",
    "\n",
    "        out = self(x, z)  # Evaluate network\n",
    "        loss_tot = 0\n",
    "\n",
    "        logratios = self._get_logratios(\n",
    "            out\n",
    "        )  # Generates concatenated flattened list of all estimated log ratios\n",
    "        if logratios is not None:\n",
    "            y = torch.zeros_like(logratios)\n",
    "            y[:num_pos, ...] = 1\n",
    "            y[num_pos:, ...] = softlabels\n",
    "            pos_weight = torch.ones_like(logratios[0]) * num_neg / num_pos\n",
    "            loss = F.binary_cross_entropy_with_logits(\n",
    "                logratios, y, reduction=\"none\", pos_weight=pos_weight\n",
    "            )\n",
    "            num_ratios = loss.shape[1]\n",
    "            loss = loss.sum() / num_neg  # Calculates batched-averaged loss\n",
    "            loss = loss - 2 * np.log(2.0) * num_ratios\n",
    "            loss_tot += loss\n",
    "\n",
    "        aux_losses = self._get_aux_losses(out)\n",
    "        if aux_losses is not None:\n",
    "            loss_tot += aux_losses.sum()\n",
    "\n",
    "        return loss_tot\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/scratch-shared/scur2012/training_data/default_limits_2e6/training_data'\n",
    "zarr_store = sl.ZarrStore(f\"{data_dir}\")\n",
    "\n",
    "train_data = zarr_store.get_dataloader(\n",
    "    num_workers=8,\n",
    "    batch_size=5,\n",
    "    idx_range=[0, int(0.95 * len(zarr_store.data.z_int))],\n",
    "    on_after_load_sample=False,\n",
    ")\n",
    "\n",
    "model = InferenceNetwork(batch_size=5, learning_rate=5e-4)\n",
    "for batch_idx, batch in enumerate(train_data):\n",
    "    \n",
    "\n",
    "    loss = model.training_step(batch, batch_idx)\n",
    "\n",
    "    break\n",
    "\n",
    "    # zero the parameter gradients\n",
    "    optimizer.zero_grad()   \n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print (batch_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0147, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from toolz.dicttoolz import valmap\n",
    "\n",
    "A = batch\n",
    "B = valmap(lambda z: torch.roll(z, 1, dims=0), A)\n",
    "\n",
    "x = A\n",
    "z = {}\n",
    "for key in B:\n",
    "    z[key] = torch.cat([A[key], B[key]])\n",
    "\n",
    "num_pos = len(list(x.values())[0])  # Number of positive examples\n",
    "num_neg = len(list(z.values())[0]) - num_pos  # Number of negative examples"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
